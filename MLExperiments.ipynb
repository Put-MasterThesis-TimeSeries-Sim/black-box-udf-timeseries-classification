{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import exists\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import classification_report\n",
    "from sktime.datatypes._panel._convert import (\n",
    "    from_multi_index_to_nested,\n",
    ")\n",
    "entry_directory = \"Raw\"\n",
    "prepared_directory = \"Prepared\"\n",
    "organised_directory = \"Organised\"\n",
    "ml_directory = \"MachineLearning\"\n",
    "seed = 42\n",
    "\n",
    "def remap_labels(label):\n",
    "    if label == \"aggregation\":\n",
    "        return 0\n",
    "    elif label == \"filtration\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def grow_snapshots(snapshot, label, snapshots):\n",
    "    if label == \"aggregation\":\n",
    "        return snapshot\n",
    "    elif label == \"filtration\":\n",
    "        return snapshot + snapshots\n",
    "    else:\n",
    "        return snapshot + 2*snapshots\n",
    "\n",
    "def read_dataset_TSLearn(udf_types, organised_directory, num_of_samples = 0, include_RAM = False, file_type = \"joined\"):\n",
    "    from tslearn.utils import to_time_series_dataset, to_time_series\n",
    "\n",
    "    full_df = pd.DataFrame()\n",
    "    for udf_type in udf_types:\n",
    "        full_df = pd.concat([full_df, pd.read_csv(f\"{organised_directory}/{udf_type}/{file_type}_{udf_type}.csv\")])\n",
    "    if num_of_samples > 0:\n",
    "        full_df = full_df[full_df.snapshot < num_of_samples]\n",
    "    \n",
    "    if include_RAM:\n",
    "        full_df[\"timeseries\"] = full_df.apply(lambda x: np.array([x.CPU, x.RAM]), axis=1)\n",
    "        full_df = full_df[full_df.snapshot < 200].groupby([\"label\", \"snapshot\"]).timeseries.apply(list).reset_index()\n",
    "        ts_series = full_df.timeseries.apply(to_time_series).to_numpy()\n",
    "    else:\n",
    "        full_df = full_df.groupby([\"label\", \"snapshot\"]).CPU.apply(np.array).reset_index()\n",
    "        ts_series = full_df.CPU.to_numpy()\n",
    "    ts_labels_str = full_df.label.to_numpy()\n",
    "    ts_labels = full_df.label.apply(remap_labels).to_numpy()\n",
    "    ts_series = to_time_series_dataset(ts_series)\n",
    "\n",
    "    return ts_labels, ts_series, ts_labels_str\n",
    "\n",
    "\n",
    "def read_dataset_sktime(udf_types, organised_directory, num_of_samples = 0, include_RAM = False, file_type = \"joined\"):\n",
    "\n",
    "    full_df = pd.DataFrame()\n",
    "    for udf_type in udf_types:\n",
    "        full_df = pd.concat([full_df, pd.read_csv(f\"{organised_directory}/{udf_type}/joined_{udf_type}.csv\")])\n",
    "    if num_of_samples > 0:\n",
    "        full_df = full_df[full_df.snapshot < num_of_samples]\n",
    "\n",
    "    ts_labels = full_df[full_df.epoch == 0.0].label.apply(remap_labels).to_numpy()\n",
    "    full_df[\"snapshot\"] = full_df.apply(lambda x: grow_snapshots(x.snapshot, x.label, num_of_samples), axis=1)\n",
    "    df = full_df.set_index([\"snapshot\", full_df.groupby(\"snapshot\").cumcount()])\n",
    "    index = pd.MultiIndex.from_product(df.index.levels, names=df.index.names)\n",
    "    output = df.reindex(index, fill_value=0).reset_index(level=1, drop=True).reset_index()\n",
    "    output[\"row_number\"] = output.groupby(\"snapshot\").cumcount()\n",
    "    if include_RAM:\n",
    "        output = output[[\"snapshot\", \"row_number\", \"CPU\", \"RAM\"]].set_index([\"snapshot\", \"row_number\"])\n",
    "    else:\n",
    "        output = output[[\"snapshot\", \"row_number\", \"CPU\"]].set_index([\"snapshot\", \"row_number\"])\n",
    "\n",
    "    return ts_labels, output\n",
    "\n",
    "def read_dataset_sktime(udf_types, organised_directory, num_of_samples = 0, include_RAM = False, file_type = \"joined\"):\n",
    "\n",
    "    full_df = pd.DataFrame()\n",
    "    for udf_type in udf_types:\n",
    "        full_df = pd.concat([full_df, pd.read_csv(f\"{organised_directory}/{udf_type}/joined_{udf_type}.csv\")])\n",
    "    if num_of_samples > 0:\n",
    "        full_df = full_df[full_df.snapshot < num_of_samples]\n",
    "\n",
    "    ts_labels = full_df[full_df.epoch == 0.0].label.apply(remap_labels).to_numpy()\n",
    "    full_df[\"snapshot\"] = full_df.apply(lambda x: grow_snapshots(x.snapshot, x.label, num_of_samples), axis=1)\n",
    "    full_df[\"row_number\"] = full_df.groupby(\"snapshot\").cumcount()\n",
    "    if include_RAM:\n",
    "        full_df = full_df[[\"snapshot\", \"row_number\", \"CPU\", \"RAM\"]].set_index([\"snapshot\", \"row_number\"])\n",
    "    else:\n",
    "        full_df = full_df[[\"snapshot\", \"row_number\", \"CPU\"]].set_index([\"snapshot\", \"row_number\"])\n",
    "    return ts_labels, from_multi_index_to_nested(full_df)\n",
    "\n",
    "def read_dataset_sktime_zeros(udf_types, organised_directory, num_of_samples = 0, include_RAM = False, file_type = \"joined\"):\n",
    "\n",
    "    full_df = pd.DataFrame()\n",
    "    for udf_type in udf_types:\n",
    "        full_df = pd.concat([full_df, pd.read_csv(f\"{organised_directory}/{udf_type}/joined_{udf_type}.csv\")])\n",
    "    if num_of_samples > 0:\n",
    "        full_df = full_df[full_df.snapshot < num_of_samples]\n",
    "\n",
    "    ts_y = full_df[full_df.epoch == 0.0].label.apply(remap_labels).to_numpy()\n",
    "    full_df[\"snapshot\"] = full_df.apply(lambda x: grow_snapshots(x.snapshot, x.label, num_of_samples), axis=1)\n",
    "    df = full_df.set_index([\"snapshot\", full_df.groupby(\"snapshot\").cumcount()])\n",
    "    index = pd.MultiIndex.from_product(df.index.levels, names=df.index.names)\n",
    "    output = df.reindex(index, fill_value=0).reset_index(level=1, drop=True).reset_index()\n",
    "    output[\"row_number\"] = output.groupby(\"snapshot\").cumcount()\n",
    "    if include_RAM:\n",
    "        ts_x = output[[\"snapshot\", \"row_number\", \"CPU\", \"RAM\"]].set_index([\"snapshot\", \"row_number\"])\n",
    "    else:\n",
    "        ts_x = output[[\"snapshot\", \"row_number\", \"CPU\"]].set_index([\"snapshot\", \"row_number\"])\n",
    "\n",
    "    return ts_y, from_multi_index_to_nested(ts_x)\n",
    "\n",
    "def wrap_classification_timer(clf, X_train, y_train, x_test, y_test):\n",
    "    start = time.time()\n",
    "    print(f\"start time: {datetime.fromtimestamp(start)}\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(classification_report(y_test, clf.predict(x_test)))\n",
    "    end = time.time()\n",
    "    print(f\"end time: {datetime.fromtimestamp(end)}\")\n",
    "    time_elapsed = (end - start)/60\n",
    "    print(f\"time elapsed: {time_elapsed} minutes.\")\n",
    "\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSLearn experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "udf_types = ['aggregation', 'filtration', 'filtration-aggregation']\n",
    "number_of_samples = 300\n",
    "\n",
    "joined_ts_labels, joined_ts_series, joined_ts_labels_str = read_dataset_TSLearn(udf_types, organised_directory, number_of_samples, True, \"joined\")\n",
    "normalized_ts_labels, normalized_ts_series, normalized_ts_labels_str = read_dataset_TSLearn(udf_types, organised_directory, number_of_samples, True, \"normalized\")\n",
    "smooth_ts_labels, smooth_ts_series, smooth_ts_labels_str = read_dataset_TSLearn(udf_types, organised_directory, number_of_samples, True, \"12_normalized_smooth\")\n",
    "\n",
    "joined_X_train, joined_X_test, joined_y_train, joined_y_test = train_test_split(joined_ts_series, joined_ts_labels, test_size=0.33, random_state=seed)\n",
    "normalized_X_train, normalized_X_test, normalized_y_train, normalized_y_test = train_test_split(normalized_ts_series, normalized_ts_labels, test_size=0.33, random_state=seed)\n",
    "smooth_X_train, smooth_X_test, smooth_y_train, smooth_y_test = train_test_split(smooth_ts_series, smooth_ts_labels, test_size=0.33, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2022-04-30 13:45:37.624882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96        71\n",
      "           1       0.98      1.00      0.99        61\n",
      "           2       0.94      0.97      0.96        66\n",
      "\n",
      "    accuracy                           0.97       198\n",
      "   macro avg       0.97      0.97      0.97       198\n",
      "weighted avg       0.97      0.97      0.97       198\n",
      "\n",
      "end time: 2022-04-30 14:01:01.625050\n",
      "time elapsed: 15.400002797444662 minutes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tslearn.neighbors import KNeighborsTimeSeriesClassifier\n",
    "\n",
    "# joined dataset\n",
    "path_to_model = f\"./{ml_directory}/knn_trained_joined.hdf5\"\n",
    "if exists(path_to_model):\n",
    "    knn_joined = KNeighborsTimeSeriesClassifier.from_hdf5(path_to_model)\n",
    "    print(classification_report(joined_y_test, knn_joined.predict(joined_X_test)))\n",
    "else:\n",
    "    knn_joined = wrap_classification_timer(KNeighborsTimeSeriesClassifier(n_neighbors=3, metric=\"dtw\", n_jobs=4), joined_X_train, joined_y_train, joined_X_test, joined_y_test)\n",
    "    knn_joined.to_hdf5(path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2022-04-30 14:01:01.741091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95        71\n",
      "           1       0.98      1.00      0.99        61\n",
      "           2       0.95      0.92      0.94        66\n",
      "\n",
      "    accuracy                           0.96       198\n",
      "   macro avg       0.96      0.96      0.96       198\n",
      "weighted avg       0.96      0.96      0.96       198\n",
      "\n",
      "end time: 2022-04-30 14:16:18.656087\n",
      "time elapsed: 15.281916602452595 minutes.\n"
     ]
    }
   ],
   "source": [
    "# normalized dataset\n",
    "path_to_model = f\"./{ml_directory}/knn_trained_normalized.hdf5\"\n",
    "if exists(path_to_model):\n",
    "    knn_normalized = KNeighborsTimeSeriesClassifier.from_hdf5(path_to_model)\n",
    "    print(classification_report(normalized_y_test, knn_normalized.predict(normalized_X_test)))\n",
    "else:\n",
    "    knn_normalized = wrap_classification_timer(KNeighborsTimeSeriesClassifier(n_neighbors=3, metric=\"dtw\", n_jobs=4), normalized_X_train, normalized_y_train, normalized_X_test, normalized_y_test)\n",
    "    knn_normalized.to_hdf5(path_to_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2022-04-30 14:16:18.745089\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91        71\n",
      "           1       0.98      1.00      0.99        61\n",
      "           2       0.92      0.86      0.89        66\n",
      "\n",
      "    accuracy                           0.93       198\n",
      "   macro avg       0.93      0.93      0.93       198\n",
      "weighted avg       0.93      0.93      0.93       198\n",
      "\n",
      "end time: 2022-04-30 14:31:28.770088\n",
      "time elapsed: 15.167083323001862 minutes.\n"
     ]
    }
   ],
   "source": [
    "# smooth dataset\n",
    "path_to_model = f\"./{ml_directory}/knn_trained_smooth.hdf5\"\n",
    "if exists(path_to_model):\n",
    "    knn_smooth = KNeighborsTimeSeriesClassifier.from_hdf5(path_to_model)\n",
    "    print(classification_report(smooth_y_test, knn_smooth.predict(smooth_X_test)))\n",
    "else:\n",
    "    knn_smooth = wrap_classification_timer(KNeighborsTimeSeriesClassifier(n_neighbors=3, metric=\"dtw\", n_jobs=4), smooth_X_train, smooth_y_train, smooth_X_test, smooth_y_test)\n",
    "    knn_smooth.to_hdf5(path_to_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miket\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tslearn\\shapelets\\shapelets.py:354: FutureWarning: The default value for 'scale' is set to False in version 0.4 to ensure backward compatibility, but is likely to change in a future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2022-04-30 14:41:35.713545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      1.00      0.53        71\n",
      "           1       0.00      0.00      0.00        61\n",
      "           2       0.00      0.00      0.00        66\n",
      "\n",
      "    accuracy                           0.36       198\n",
      "   macro avg       0.12      0.33      0.18       198\n",
      "weighted avg       0.13      0.36      0.19       198\n",
      "\n",
      "end time: 2022-04-30 14:47:08.344848\n",
      "time elapsed: 5.543855047225952 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miket\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "C:\\Users\\Miket\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "C:\\Users\\Miket\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "from tslearn.shapelets import LearningShapelets, grabocka_params_to_shapelet_size_dict\n",
    "from tensorflow import optimizers as opt\n",
    "\n",
    "path_to_model = f\"./{ml_directory}/shp_trained_joined.hdf5\"\n",
    "if exists(path_to_model):\n",
    "    shp_joined = LearningShapelets.from_hdf5(path_to_model)\n",
    "    print(classification_report(joined_y_test, shp_joined.predict(joined_X_test)))\n",
    "else:\n",
    "    n_ts, ts_sz = joined_X_train.shape[:2]\n",
    "    n_classes = len(set(joined_y_train))\n",
    "    shapelet_sizes = grabocka_params_to_shapelet_size_dict(n_ts=n_ts,\n",
    "                                                        ts_sz=ts_sz,\n",
    "                                                        n_classes=n_classes,\n",
    "                                                        l=0.06,\n",
    "                                                        r=1)\n",
    "    shp_joined = wrap_classification_timer(LearningShapelets(n_shapelets_per_size=shapelet_sizes,\n",
    "                            optimizer=opt.Adam(.01),\n",
    "                            batch_size=16,\n",
    "                            weight_regularizer=.01,\n",
    "                            max_iter=200,\n",
    "                            random_state=seed,\n",
    "                            verbose=0), joined_X_train, joined_y_train, joined_X_test, joined_y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miket\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tslearn\\shapelets\\shapelets.py:354: FutureWarning: The default value for 'scale' is set to False in version 0.4 to ensure backward compatibility, but is likely to change in a future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2022-04-30 14:47:08.467856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      1.00      0.53        71\n",
      "           1       0.00      0.00      0.00        61\n",
      "           2       0.00      0.00      0.00        66\n",
      "\n",
      "    accuracy                           0.36       198\n",
      "   macro avg       0.12      0.33      0.18       198\n",
      "weighted avg       0.13      0.36      0.19       198\n",
      "\n",
      "end time: 2022-04-30 14:53:23.806428\n",
      "time elapsed: 6.2556428670883175 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miket\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "C:\\Users\\Miket\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "C:\\Users\\Miket\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "path_to_model = f\"./{ml_directory}/shp_trained_normalized.hdf5\"\n",
    "if exists(path_to_model):\n",
    "    shp_normalized = LearningShapelets.from_hdf5(path_to_model)\n",
    "    print(classification_report(normalized_y_test, shp_normalized.predict(normalized_X_test)))\n",
    "else:\n",
    "    n_ts, ts_sz = normalized_X_train.shape[:2]\n",
    "    n_classes = len(set(normalized_y_train))\n",
    "    shapelet_sizes = grabocka_params_to_shapelet_size_dict(n_ts=n_ts,\n",
    "                                                        ts_sz=ts_sz,\n",
    "                                                        n_classes=n_classes,\n",
    "                                                        l=0.06,\n",
    "                                                        r=1)\n",
    "    shp_normalized = wrap_classification_timer(LearningShapelets(n_shapelets_per_size=shapelet_sizes,\n",
    "                            optimizer=opt.Adam(.01),\n",
    "                            batch_size=16,\n",
    "                            weight_regularizer=.01,\n",
    "                            max_iter=200,\n",
    "                            random_state=seed,\n",
    "                            verbose=0), normalized_X_train, normalized_y_train, normalized_X_test, normalized_y_test)\n",
    "    # shp_normalized.to_hdf5(path_to_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miket\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tslearn\\shapelets\\shapelets.py:354: FutureWarning: The default value for 'scale' is set to False in version 0.4 to ensure backward compatibility, but is likely to change in a future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2022-04-30 14:53:23.887428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      1.00      0.53        71\n",
      "           1       0.00      0.00      0.00        61\n",
      "           2       0.00      0.00      0.00        66\n",
      "\n",
      "    accuracy                           0.36       198\n",
      "   macro avg       0.12      0.33      0.18       198\n",
      "weighted avg       0.13      0.36      0.19       198\n",
      "\n",
      "end time: 2022-04-30 14:59:10.185378\n",
      "time elapsed: 5.77163249651591 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miket\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "C:\\Users\\Miket\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "C:\\Users\\Miket\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "path_to_model = f\"./{ml_directory}/shp_trained_smooth.hdf5\"\n",
    "if exists(path_to_model):\n",
    "    shp_smooth = LearningShapelets.from_hdf5(path_to_model)\n",
    "    print(classification_report(smooth_y_test, shp_smooth.predict(smooth_X_test)))\n",
    "else:\n",
    "    n_ts, ts_sz = smooth_X_train.shape[:2]\n",
    "    n_classes = len(set(smooth_y_train))\n",
    "    shapelet_sizes = grabocka_params_to_shapelet_size_dict(n_ts=n_ts,\n",
    "                                                        ts_sz=ts_sz,\n",
    "                                                        n_classes=n_classes,\n",
    "                                                        l=0.06,\n",
    "                                                        r=1)\n",
    "    shp_smooth = wrap_classification_timer(LearningShapelets(n_shapelets_per_size=shapelet_sizes,\n",
    "                            optimizer=opt.Adam(.01),\n",
    "                            batch_size=16,\n",
    "                            weight_regularizer=.01,\n",
    "                            max_iter=200,\n",
    "                            random_state=seed,\n",
    "                            verbose=0), smooth_X_train, smooth_y_train, smooth_X_test, smooth_y_test)\n",
    "    # shp_smooth.to_hdf5(path_to_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2022-04-30 14:59:10.283377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.03        71\n",
      "           1       1.00      0.08      0.15        61\n",
      "           2       0.34      1.00      0.51        66\n",
      "\n",
      "    accuracy                           0.36       198\n",
      "   macro avg       0.78      0.37      0.23       198\n",
      "weighted avg       0.78      0.36      0.23       198\n",
      "\n",
      "end time: 2022-04-30 15:21:10.238334\n",
      "time elapsed: 21.99924928744634 minutes.\n"
     ]
    }
   ],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "\n",
    "# joined dataset\n",
    "path_to_model = f\"./{ml_directory}/km_trained_joined.hdf5\"\n",
    "if exists(path_to_model):\n",
    "    km_joined = TimeSeriesKMeans.from_hdf5(path_to_model)\n",
    "    print(classification_report(joined_y_test, km_joined.predict(joined_X_test)))\n",
    "else:\n",
    "    km_joined = wrap_classification_timer(TimeSeriesKMeans(n_clusters=3, metric=\"dtw\", n_jobs=4, random_state = seed, max_iter_barycenter=5), joined_X_train, joined_y_train, joined_X_test, joined_y_test)\n",
    "    km_joined.to_hdf5(path_to_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.31      0.36        71\n",
      "           1       0.53      0.13      0.21        61\n",
      "           2       0.44      0.88      0.59        66\n",
      "\n",
      "    accuracy                           0.44       198\n",
      "   macro avg       0.47      0.44      0.39       198\n",
      "weighted avg       0.47      0.44      0.39       198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "# normalized dataset\n",
    "path_to_model = f\"./{ml_directory}/km_trained_normalized.hdf5\"\n",
    "if exists(path_to_model):\n",
    "    km_normalized = TimeSeriesKMeans.from_hdf5(path_to_model)\n",
    "    print(classification_report(normalized_y_test, km_normalized.predict(normalized_X_test)))\n",
    "else:\n",
    "    km_normalized = wrap_classification_timer(TimeSeriesKMeans(n_clusters=3, metric=\"dtw\", n_jobs=4, random_state = seed, max_iter_barycenter=5), normalized_X_train, normalized_y_train, normalized_X_test, normalized_y_test)\n",
    "    km_normalized.to_hdf5(path_to_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth dataset\n",
    "path_to_model = f\"./{ml_directory}/km_trained_smooth.hdf5\"\n",
    "if exists(path_to_model):\n",
    "    km_smooth = TimeSeriesKMeans.from_hdf5(path_to_model)\n",
    "    print(classification_report(smooth_y_test, km_smooth.predict(smooth_X_test)))\n",
    "else:\n",
    "    km_smooth = wrap_classification_timer(TimeSeriesKMeans(n_clusters=3, metric=\"dtw\", n_jobs=4, random_state = seed, max_iter_barycenter=5), smooth_X_train, smooth_y_train, smooth_X_test, smooth_y_test)\n",
    "    km_smooth.to_hdf5(path_to_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "udf_types = ['aggregation', 'filtration', 'filtration-aggregation']\n",
    "number_of_samples = 300\n",
    "joined_sk_labels, joined_sk_series = read_dataset_sktime_zeros(udf_types, organised_directory, number_of_samples, True, \"joined\")\n",
    "normalized_sk_labels, normalized_sk_series = read_dataset_sktime_zeros(udf_types, organised_directory, number_of_samples, True, \"normalized\")\n",
    "smooth_sk_labels, smooth_sk_series = read_dataset_sktime_zeros(udf_types, organised_directory, number_of_samples, True, \"12_normalized_smooth\")\n",
    "\n",
    "joined_X_train, joined_X_test, joined_y_train, joined_y_test = train_test_split(joined_sk_series, joined_sk_labels, test_size=0.33, random_state=seed)\n",
    "normalized_X_train, normalized_X_test, normalized_y_train, normalized_y_test = train_test_split(normalized_sk_series, normalized_sk_labels, test_size=0.33, random_state=seed)\n",
    "smooth_X_train, smooth_X_test, smooth_y_train, smooth_y_test = train_test_split(smooth_sk_series, smooth_sk_labels, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2022-05-03 12:42:42.650865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        94\n",
      "           1       1.00      1.00      1.00       117\n",
      "           2       0.98      0.98      0.98        86\n",
      "\n",
      "    accuracy                           0.99       297\n",
      "   macro avg       0.99      0.99      0.99       297\n",
      "weighted avg       0.99      0.99      0.99       297\n",
      "\n",
      "end time: 2022-05-03 12:43:58.198869\n",
      "time elapsed: 1.2591334104537963 minutes.\n"
     ]
    }
   ],
   "source": [
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "\n",
    "rocket = wrap_classification_timer(RocketClassifier(rocket_transform=\"multirocket\"), joined_X_train, joined_y_train, joined_X_test, joined_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2022-05-03 12:13:14.146583\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        94\n",
      "           1       1.00      1.00      1.00       117\n",
      "           2       0.99      0.98      0.98        86\n",
      "\n",
      "    accuracy                           0.99       297\n",
      "   macro avg       0.99      0.99      0.99       297\n",
      "weighted avg       0.99      0.99      0.99       297\n",
      "\n",
      "end time: 2022-05-03 12:14:51.254236\n",
      "time elapsed: 1.6184608777364096 minutes.\n"
     ]
    }
   ],
   "source": [
    "rocket = wrap_classification_timer(RocketClassifier(rocket_transform=\"multirocket\"), normalized_X_train, normalized_y_train, normalized_X_test, normalized_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2022-05-03 12:14:51.356232\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        94\n",
      "           1       1.00      1.00      1.00       117\n",
      "           2       0.99      0.98      0.98        86\n",
      "\n",
      "    accuracy                           0.99       297\n",
      "   macro avg       0.99      0.99      0.99       297\n",
      "weighted avg       0.99      0.99      0.99       297\n",
      "\n",
      "end time: 2022-05-03 12:16:21.932329\n",
      "time elapsed: 1.509601620833079 minutes.\n"
     ]
    }
   ],
   "source": [
    "rocket = wrap_classification_timer(RocketClassifier(rocket_transform=\"multirocket\"), smooth_X_train, smooth_y_train, smooth_X_test, smooth_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HIVECOTEV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2022-05-03 12:16:22.258326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        94\n",
      "           1       1.00      1.00      1.00       117\n",
      "           2       0.93      0.97      0.95        86\n",
      "\n",
      "    accuracy                           0.97       297\n",
      "   macro avg       0.97      0.97      0.97       297\n",
      "weighted avg       0.97      0.97      0.97       297\n",
      "\n",
      "end time: 2022-05-03 12:24:47.263344\n",
      "time elapsed: 8.416750299930573 minutes.\n"
     ]
    }
   ],
   "source": [
    "from sktime.classification.hybrid import HIVECOTEV2\n",
    "\n",
    "hive = wrap_classification_timer(HIVECOTEV2(time_limit_in_minutes=2), joined_X_train, joined_y_train, joined_X_test, joined_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2022-05-03 12:24:47.439320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        94\n",
      "           1       1.00      1.00      1.00       117\n",
      "           2       0.94      0.98      0.96        86\n",
      "\n",
      "    accuracy                           0.98       297\n",
      "   macro avg       0.97      0.97      0.97       297\n",
      "weighted avg       0.98      0.98      0.98       297\n",
      "\n",
      "end time: 2022-05-03 12:32:58.088857\n",
      "time elapsed: 8.177492296695709 minutes.\n"
     ]
    }
   ],
   "source": [
    "hive = wrap_classification_timer(HIVECOTEV2(time_limit_in_minutes=2), normalized_X_train, normalized_y_train, normalized_X_test, normalized_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2022-05-03 12:32:58.231866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96        94\n",
      "           1       1.00      1.00      1.00       117\n",
      "           2       0.96      0.95      0.96        86\n",
      "\n",
      "    accuracy                           0.98       297\n",
      "   macro avg       0.97      0.97      0.97       297\n",
      "weighted avg       0.98      0.98      0.98       297\n",
      "\n",
      "end time: 2022-05-03 12:41:02.038855\n",
      "time elapsed: 8.063449827829997 minutes.\n"
     ]
    }
   ],
   "source": [
    "hive = wrap_classification_timer(HIVECOTEV2(time_limit_in_minutes=2), smooth_X_train, smooth_y_train, smooth_X_test, smooth_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DrCIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2022-05-03 12:56:14.889016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        94\n",
      "           1       1.00      1.00      1.00       117\n",
      "           2       0.99      0.95      0.97        86\n",
      "\n",
      "    accuracy                           0.98       297\n",
      "   macro avg       0.98      0.98      0.98       297\n",
      "weighted avg       0.98      0.98      0.98       297\n",
      "\n",
      "end time: 2022-05-03 13:19:53.938897\n",
      "time elapsed: 23.650831345717112 minutes.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sktime.transformations.panel.compose import ColumnConcatenator\n",
    "from sktime.classification.interval_based import DrCIF\n",
    "\n",
    "steps = [\n",
    "    (\"concatenate\", ColumnConcatenator()),\n",
    "    (\"classify\", DrCIF(n_estimators=10)),\n",
    "]\n",
    "\n",
    "cif = wrap_classification_timer(Pipeline(steps), joined_X_train, joined_y_train, joined_X_test, joined_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2022-05-03 13:21:49.250322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        94\n",
      "           1       1.00      1.00      1.00       117\n",
      "           2       0.97      0.97      0.97        86\n",
      "\n",
      "    accuracy                           0.98       297\n",
      "   macro avg       0.98      0.98      0.98       297\n",
      "weighted avg       0.98      0.98      0.98       297\n",
      "\n",
      "end time: 2022-05-03 13:40:37.700886\n",
      "time elapsed: 18.807509406407675 minutes.\n"
     ]
    }
   ],
   "source": [
    "cif = wrap_classification_timer(Pipeline(steps), normalized_X_train, normalized_y_train, normalized_X_test, normalized_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2022-05-03 13:40:37.800889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96        94\n",
      "           1       1.00      1.00      1.00       117\n",
      "           2       0.96      0.95      0.96        86\n",
      "\n",
      "    accuracy                           0.98       297\n",
      "   macro avg       0.97      0.97      0.97       297\n",
      "weighted avg       0.98      0.98      0.98       297\n",
      "\n",
      "end time: 2022-05-03 13:59:39.859255\n",
      "time elapsed: 19.03430610895157 minutes.\n"
     ]
    }
   ],
   "source": [
    "cif = wrap_classification_timer(Pipeline(steps), smooth_X_train, smooth_y_train, smooth_X_test, smooth_y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9df95f7668529cec28adbb33d37156c0ce628a414db3492516415ddc99949cd4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
